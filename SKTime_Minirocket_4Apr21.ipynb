{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SKTime_Minirocket_4Apr21.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNBsjGs8rNmQJ6hLWsY/e6B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidurpani/TimeSeriesAnalysisWithPython/blob/master/SKTime_Minirocket_4Apr21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xXEUd5h9CNI"
      },
      "source": [
        "\n",
        "## **MiniRocket**\n",
        "\n",
        "MiniRocket transforms input time series using a small, fixed set of convolutional kernels. MiniRocket uses PPV pooling to compute a single feature for each of the resulting feature maps (i.e., the proportion of positive values). The transformed features are used to train a linear classifier.\n",
        "\n",
        "Dempster A, Schmidt DF, Webb GI (2020) MiniRocket: A Very Fast (Almost) Deterministic Transform for Time Series Classification arXiv:2012.08791\n",
        "1 Univariate Time Series\n",
        "1.1 Imports\n",
        "\n",
        "Import example data, MiniRocket, RidgeClassifierCV (scikit-learn), and NumPy.\n",
        "\n",
        "Note: MiniRocket and MiniRocketMultivariate are compiled by Numba on import. The compiled functions are cached, so this should only happen once (i.e., the first time you import MiniRocket or MiniRocketMultivariate).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxrK3yXGnor2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f506fff-0fd6-4da5-fccf-da17c2de2ae9"
      },
      "source": [
        "!pip install --upgrade numba"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numba\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/73/d9c127eddbe3c105a33379d425b88f9dca249a6eddf39ce886494d49c3f9/numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba) (1.19.5)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/25/2b4015e2b0c3be2efa6870cf2cf2bd969dd0e5f937476fc13c102209df32/llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (54.2.0)\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.36.0 numba-0.53.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87fjMpVBmkdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e86fab-fe22-4cb2-fcad-6089b489fcc3"
      },
      "source": [
        "!pip install sktime"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sktime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/da/50152302ec50c4be412f028edd9173b66121ed7af80473cca47ef6eae65b/sktime-0.5.3-cp37-cp37m-manylinux2014_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sktime) (0.36.2)\n",
            "Collecting statsmodels>=0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/69/8eef30a6237c54f3c0b524140e2975f4b1eea3489b45eb3339574fc8acee/statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from sktime) (0.53.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from sktime) (1.19.5)\n",
            "Collecting scikit-learn>=0.23.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.1->sktime) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->sktime) (0.36.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->sktime) (2.8.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->sktime) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels>=0.12.1->sktime) (1.15.0)\n",
            "Installing collected packages: statsmodels, threadpoolctl, scikit-learn, sktime\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.1 sktime-0.5.3 statsmodels-0.12.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTOuFI8qm9V7",
        "outputId": "5985603f-abe8-4847-d8ea-a5116859950d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sktime.datasets import load_arrow_head  # univariate dataset\n",
        "from sktime.datasets.base import load_basic_motions  # multivariate dataset\n",
        "from sktime.transformations.panel.rocket import MiniRocket, MiniRocketMultivariate"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:365: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl46NoQC9Uza"
      },
      "source": [
        "\n",
        "### 1.2 Load the Training Data\n",
        "\n",
        "For more details on the data set, see the univariate time series classification notebook.\n",
        "\n",
        "Note: Input time series must be at least of length 9. Pad shorter time series using, e.g., PaddingTransformer (sktime.transformers.panel.padder).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0DAvRaQnfec"
      },
      "source": [
        "X_train, y_train = load_arrow_head(split=\"train\", return_X_y=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlFRjfyf-6E5"
      },
      "source": [
        "### 1.3 Initialise MiniRocket and Transform the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWbHFrJb-7uz"
      },
      "source": [
        "minirocket = MiniRocket()  # by default, MiniRocket uses ~10,000 kernels\n",
        "minirocket.fit(X_train)\n",
        "X_train_transform = minirocket.transform(X_train)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-SMAdbY_Qoj"
      },
      "source": [
        "\n",
        "### 1.4 Fit a Classifier\n",
        "\n",
        "We suggest using RidgeClassifierCV (scikit-learn) for smaller datasets (fewer than ~10,000 training examples), and using logistic regression trained using stochastic gradient descent for larger datasets.\n",
        "\n",
        "Note: For larger datasets, this means integrating MiniRocket with stochastic gradient descent such that the transform is performed per minibatch, not simply substituting RidgeClassifierCV for, e.g., LogisticRegression.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oCrUSck_Ivc",
        "outputId": "17dd0e14-fa94-4951-da38-d0644ddb20a8"
      },
      "source": [
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "classifier.fit(X_train_transform, y_train)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
              "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
              "       2.15443469e+02, 1.00000000e+03]),\n",
              "                  normalize=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnP-WRiXHe5O"
      },
      "source": [
        "1.5 Load and Transform the Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecPPFePE_XNo"
      },
      "source": [
        "X_test, y_test = load_arrow_head(split=\"test\", return_X_y=True)\n",
        "X_test_transform = minirocket.transform(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Q8SVK_H3-g"
      },
      "source": [
        "**1.6 Classify the Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZvO1rPsHpI9",
        "outputId": "d4cb3300-d5f2-4c6d-d667-3ee33ab909af"
      },
      "source": [
        "classifier.score(X_test_transform, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYXI0VJlIZbn"
      },
      "source": [
        "## **2 Multivariate Time Series**\n",
        "We can use the multivariate version of MiniRocket for multivariate time series input.\n",
        "\n",
        "# 2.1 Imports\n",
        "\n",
        "Import MiniRocketMultivariate.\n",
        "\n",
        "Note: MiniRocketMultivariate compiles via Numba on import."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4kQsslcIudp"
      },
      "source": [
        "# 2.2 Load the Training Data\n",
        "\n",
        "Note: Input time series must be at least of length 9. Pad shorter time series using, e.g., PaddingTransformer (sktime.transformers.panel.padder)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr3-M8_uIBGJ"
      },
      "source": [
        "X_train, y_train = load_basic_motions(split=\"train\", return_X_y=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUEpVF5oJBDs"
      },
      "source": [
        "# 2.3 Initialise MiniRocket and Transform the Training Data¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9KCPImjI7j9"
      },
      "source": [
        "minirocket_multi = MiniRocketMultivariate()\n",
        "minirocket_multi.fit(X_train)\n",
        "X_train_transform = minirocket_multi.transform(X_train)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPlqVbk1Jxeo"
      },
      "source": [
        "# 2.4 Fit a Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMG4ewXOJ2Wp",
        "outputId": "3697f910-c695-4844-bfb4-344ea05b3cb2"
      },
      "source": [
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "classifier.fit(X_train_transform, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
              "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
              "       2.15443469e+02, 1.00000000e+03]),\n",
              "                  normalize=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkai4c5dJ930"
      },
      "source": [
        "# 2.5 Load and Transform the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2c-XvYUKCUl"
      },
      "source": [
        "X_test, y_test = load_basic_motions(split=\"test\", return_X_y=True)\n",
        "X_test_transform = minirocket_multi.transform(X_test)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0JFhengJoa_"
      },
      "source": [
        "# 2.6 Classify the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji7yj1YDJJ0w",
        "outputId": "fe938107-96fb-45fc-c475-d3836c2bd20c"
      },
      "source": [
        "classifier.score(X_test_transform, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4HQea7vKUeO"
      },
      "source": [
        "## **3 Pipeline Example**\n",
        "\n",
        "We can use MiniRocket together with RidgeClassifierCV (or another classifier) in a pipeline. We can then use the pipeline like a self-contained classifier, with a single call to fit, and without having to separately transform the data, etc.\n",
        "\n",
        "## 3.1 Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-hTmnhXKcVU"
      },
      "source": [
        "# 3.2 Initialise the Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8UFEISOKbfC"
      },
      "source": [
        "minirocket_pipeline = make_pipeline(\n",
        "    MiniRocket(), RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize=True)\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1y5Ne6lKy0p"
      },
      "source": [
        "## 3.3 Load and Fit the Training Data\n",
        "\n",
        "Note: Input time series must be at least of length 9. Pad shorter time series using, e.g., PaddingTransformer (sktime.transformers.panel.padder)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqOx_IFzKKUD",
        "outputId": "9990faf3-bbed-436e-ad27-88ca6819d838"
      },
      "source": [
        "X_train, y_train = load_arrow_head(split=\"train\", return_X_y=True)\n",
        "\n",
        "# it is necessary to pass y_train to the pipeline\n",
        "# y_train is not used for the transform, but it is used by the classifier\n",
        "minirocket_pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('minirocket', MiniRocket()),\n",
              "                ('ridgeclassifiercv',\n",
              "                 RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
              "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
              "       2.15443469e+02, 1.00000000e+03]),\n",
              "                                   normalize=True))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67tMogF34sXs"
      },
      "source": [
        "### 3.4 Load and Classify the Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBU2g3_S37FV",
        "outputId": "160954b9-c0fc-48c2-86b1-b51c41e3249b"
      },
      "source": [
        "X_test, y_test = load_arrow_head(split=\"test\", return_X_y=True)\n",
        "\n",
        "minirocket_pipeline.score(X_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8514285714285714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB1rA3ZK4_A1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}